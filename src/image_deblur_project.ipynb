{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ku2vNxq_K62K",
        "outputId": "6dd6131a-6aa0-4186-ba07-e2269d225a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'image-deblur' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Emeika/image-deblur.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm781KC4LUAx",
        "outputId": "b9506b87-bef3-4fd2-fda2-e28b40095313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'image-deblur/'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd image-deblur/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtnp6ZXaHVkQ"
      },
      "source": [
        "***Import Modules***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joRZ4p4VUAF5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Dense, Reshape, Conv2D, UpSampling2D, Input, MaxPooling2D, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ5VCLZOFpaa"
      },
      "source": [
        "!***Extract features into a feature vector and flatten them onto a csv***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y4nAtQiR02C"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_images(image_folder, label):\n",
        "    data = []\n",
        "    for file in tqdm(sorted(os.listdir(image_folder))):\n",
        "        if any(file.endswith(extension) for extension in ['.jpg', '.JPG']):\n",
        "            image_path = os.path.join(image_folder, file)\n",
        "            image = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n",
        "            image_flattened = image.flatten()  # Flatten the image\n",
        "            image_flattened_str = ','.join(map(str, image_flattened))  # Convert to a single string\n",
        "            data.append([image_path, image_flattened_str, label])  # Add image path and label\n",
        "    return data\n",
        "\n",
        "# Extract features\n",
        "blur_features = load_and_preprocess_images('/content/image-deblur/resized_dataset/blur', label=0)\n",
        "sharp_features = load_and_preprocess_images('/content/image-deblur/resized_dataset/sharp', label=1)\n",
        "\n",
        "# Combine data and create a DataFrame\n",
        "columns = ['image_path', 'image_features', 'label']\n",
        "data = sharp_features + blur_features\n",
        "features_df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Save to CSV\n",
        "features_df.to_csv('image_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2h8zbDfReAx",
        "outputId": "9783b2da-7c30-4fcb-d9d4-e2e2db2cfd74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 350/350 [00:11<00:00, 29.82it/s]\n",
            "100%|██████████| 350/350 [00:15<00:00, 22.87it/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_and_preprocess_images(image_folder, label, prefix):\n",
        "    data = []\n",
        "    for idx, file in enumerate(tqdm(sorted(os.listdir(image_folder)))):\n",
        "        if any(file.endswith(extension) for extension in ['.jpg', '.JPG']):\n",
        "            image_path = os.path.join(image_folder, file)\n",
        "            image = load_img(image_path, target_size=(128, 128))\n",
        "            image_array = img_to_array(image).astype('float32') / 255\n",
        "            image_flattened = image_array.flatten()  # Flatten the image\n",
        "            image_flattened_str = ','.join(map(str, image_flattened))  # Convert to a single string\n",
        "            # Use a prefix (e.g., \"blur\" or \"sharp\") and an index to pair images\n",
        "            pair_id = f\"{prefix}_{idx}\"\n",
        "            data.append([image_path, image_flattened_str, label, pair_id])  # Add pair_id\n",
        "    return data\n",
        "\n",
        "# Extract features\n",
        "blur_features = load_and_preprocess_images('/content/image-deblur/resized_dataset/blur', label=0, prefix='blur')\n",
        "sharp_features = load_and_preprocess_images('/content/image-deblur/resized_dataset/sharp', label=1, prefix='sharp')\n",
        "\n",
        "# Combine data and create a DataFrame\n",
        "columns = ['image_path', 'image_features', 'label', 'pair_id']\n",
        "data = sharp_features + blur_features\n",
        "features_df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Save to CSV\n",
        "features_df.to_csv('image_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIaN9Ym_HMIn"
      },
      "source": [
        "***Load Data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vHdjbJ2ks6u",
        "outputId": "c25c2040-7856-4345-9ae2-30e29f3bcae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(700, 128, 128, 3)\n",
            "(700,)\n",
            "(700,)\n"
          ]
        }
      ],
      "source": [
        "def load_images_from_csv(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    image_paths = df['image_path'].values\n",
        "    labels = df['label'].values\n",
        "    image_data = df['image_features'].apply(lambda x: np.fromstring(x, sep=',')).values\n",
        "    images = np.array([img.reshape(128, 128, 3) for img in image_data])  # Reshape to original dimensions\n",
        "    return images, image_paths, labels\n",
        "\n",
        "# Load images from CSV\n",
        "X, image_paths, y = load_images_from_csv('image_data.csv')\n",
        "\n",
        "print(X.shape)  # Should be (num_images, 128, 128, 3)\n",
        "print(image_paths.shape)  # Should be (num_images,)\n",
        "print(y.shape)  # Should be (num_images,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aONSiNmSRlpp",
        "outputId": "b9f86ff7-52c5-45af-ae15-8b17bbba2c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(350, 128, 128, 3)\n",
            "(350, 128, 128, 3)\n",
            "(350, 700)\n",
            "(350, 700)\n"
          ]
        }
      ],
      "source": [
        "def load_images_from_csv(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    image_paths = df['image_path'].values\n",
        "    labels = df['label'].values\n",
        "    pair_ids = df['pair_id'].values\n",
        "    image_data = df['image_features'].apply(lambda x: np.fromstring(x, sep=',')).values\n",
        "    images = np.array([img.reshape(128, 128, 3) for img in image_data])  # Reshape to original dimensions\n",
        "\n",
        "    # Create dictionaries to store blur and sharp images by pair_id\n",
        "    blur_images = {}\n",
        "    sharp_images = {}\n",
        "\n",
        "    for path, label, pair_id, image in zip(image_paths, labels, pair_ids, images):\n",
        "        if label == 0:\n",
        "            blur_images[pair_id] = image\n",
        "        else:\n",
        "            sharp_images[pair_id] = image\n",
        "\n",
        "    # Create lists to store the paired images\n",
        "    paired_blur_images = []\n",
        "    paired_sharp_images = []\n",
        "    paired_image_paths = []\n",
        "    paired_labels = []\n",
        "\n",
        "    for pair_id in blur_images.keys():\n",
        "        if pair_id.replace('blur', 'sharp') in sharp_images:\n",
        "            paired_blur_images.append(blur_images[pair_id])\n",
        "            paired_sharp_images.append(sharp_images[pair_id.replace('blur', 'sharp')])\n",
        "            paired_image_paths.append(image_paths)\n",
        "            paired_labels.append(labels)\n",
        "\n",
        "    return (np.array(paired_blur_images), np.array(paired_sharp_images),\n",
        "            np.array(paired_image_paths), np.array(paired_labels))\n",
        "\n",
        "# Load images from CSV\n",
        "blur_images, sharp_images, image_paths, y = load_images_from_csv('image_data.csv')\n",
        "\n",
        "print(blur_images.shape)  # Should be (num_images, 128, 128, 3)\n",
        "print(sharp_images.shape)  # Should be (num_images, 128, 128, 3)\n",
        "print(image_paths.shape)  # Should be (num_images,)\n",
        "print(y.shape)  # Should be (num_images,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuvWq5lH2EYq",
        "outputId": "7184af63-e92a-4a54-e827-86fff9bb10da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(280, 128, 128, 3) (280, 128, 128, 3) (70, 128, 128, 3) (70, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "def load_images_from_csv(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    image_paths = df['image_path'].values\n",
        "    labels = df['label'].values\n",
        "    image_data = df['image_features'].apply(lambda x: np.fromstring(x, sep=',')).values\n",
        "    images = np.array([img.reshape(128, 128, 3) for img in image_data])  # Reshape to original dimensions\n",
        "    return images, image_paths, labels\n",
        "\n",
        "# Load images from CSV\n",
        "images, image_paths, labels = load_images_from_csv('image_data.csv')\n",
        "\n",
        "# Split into sharp and blur images\n",
        "sharp_images = images[labels == 1]\n",
        "blur_images = images[labels == 0]\n",
        "\n",
        "# Split into train and test sets\n",
        "split_size = int(len(sharp_images) * 0.8)\n",
        "x_train, x_test = blur_images[:split_size], blur_images[split_size:]\n",
        "y_train, y_test = sharp_images[:split_size], sharp_images[split_size:]\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkU6o8yBGe5R"
      },
      "source": [
        "***Train Model by Split into Training, Testing and Validation set using kfolds cross validation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AjJngwCa8oDP",
        "outputId": "97481e6d-b6d0-4aab-90ff-7646878e5d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 162ms/step - loss: 0.0544 - val_loss: 0.0136\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0120 - val_loss: 0.0075\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0072 - val_loss: 0.0058\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - loss: 0.0060 - val_loss: 0.0049\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0052 - val_loss: 0.0044\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0041 - val_loss: 0.0052\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - loss: 0.0046 - val_loss: 0.0039\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0034 - val_loss: 0.0037\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0036 - val_loss: 0.0042\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0041 - val_loss: 0.0038\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0034 - val_loss: 0.0034\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.0036 - val_loss: 0.0032\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - loss: 0.0030 - val_loss: 0.0031\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0026 - val_loss: 0.0021\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0012 - val_loss: 0.0015\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0016 - val_loss: 0.0020\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0014 - val_loss: 0.0015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Fold 2\n",
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 0.0507 - val_loss: 0.0123\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0100 - val_loss: 0.0066\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0069 - val_loss: 0.0058\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0055 - val_loss: 0.0046\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0048 - val_loss: 0.0042\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0047 - val_loss: 0.0042\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0045 - val_loss: 0.0037\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0041 - val_loss: 0.0039\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0040 - val_loss: 0.0035\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0038 - val_loss: 0.0035\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0037 - val_loss: 0.0034\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0038 - val_loss: 0.0031\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0032 - val_loss: 0.0030\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0039 - val_loss: 0.0028\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0033 - val_loss: 0.0024\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0029 - val_loss: 0.0026\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0029 - val_loss: 0.0022\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0038 - val_loss: 0.0023\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0020 - val_loss: 0.0017\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0019 - val_loss: 0.0030\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0018 - val_loss: 0.0014\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0017 - val_loss: 0.0013\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0017 - val_loss: 0.0012\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0019 - val_loss: 0.0012\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0015 - val_loss: 0.0012\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0015 - val_loss: 0.0012\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0015 - val_loss: 0.0012\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0013 - val_loss: 0.0011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Fold 3\n",
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - loss: 0.0535 - val_loss: 0.0110\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0108 - val_loss: 0.0065\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0073 - val_loss: 0.0064\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0064 - val_loss: 0.0049\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0051 - val_loss: 0.0047\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0044 - val_loss: 0.0041\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0045 - val_loss: 0.0037\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0041 - val_loss: 0.0035\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0037 - val_loss: 0.0040\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0038 - val_loss: 0.0041\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0037 - val_loss: 0.0034\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0036 - val_loss: 0.0029\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0040 - val_loss: 0.0031\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0032 - val_loss: 0.0027\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0029 - val_loss: 0.0031\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 0.0026 - val_loss: 0.0027\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0024 - val_loss: 0.0022\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0022 - val_loss: 0.0024\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0020 - val_loss: 0.0017\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0017 - val_loss: 0.0023\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0014 - val_loss: 0.0013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Fold 4\n",
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 0.0539 - val_loss: 0.0166\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0136 - val_loss: 0.0080\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0075 - val_loss: 0.0064\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0059 - val_loss: 0.0057\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0054 - val_loss: 0.0048\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0049 - val_loss: 0.0043\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0041 - val_loss: 0.0041\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0040 - val_loss: 0.0047\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0042 - val_loss: 0.0036\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0036 - val_loss: 0.0031\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0033 - val_loss: 0.0038\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - loss: 0.0035 - val_loss: 0.0029\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0029 - val_loss: 0.0043\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0030 - val_loss: 0.0025\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0028 - val_loss: 0.0024\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0029 - val_loss: 0.0021\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0022 - val_loss: 0.0014\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0013 - val_loss: 0.0015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Fold 5\n",
            "Epoch 1/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - loss: 0.0522 - val_loss: 0.0147\n",
            "Epoch 2/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - loss: 0.0118 - val_loss: 0.0081\n",
            "Epoch 3/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0073 - val_loss: 0.0064\n",
            "Epoch 4/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0056 - val_loss: 0.0058\n",
            "Epoch 5/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0056 - val_loss: 0.0063\n",
            "Epoch 6/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0048 - val_loss: 0.0050\n",
            "Epoch 7/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0043 - val_loss: 0.0047\n",
            "Epoch 8/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0038 - val_loss: 0.0045\n",
            "Epoch 9/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0035 - val_loss: 0.0062\n",
            "Epoch 10/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 11/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0032 - val_loss: 0.0041\n",
            "Epoch 12/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 13/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0029 - val_loss: 0.0040\n",
            "Epoch 14/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0030 - val_loss: 0.0042\n",
            "Epoch 15/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0031 - val_loss: 0.0034\n",
            "Epoch 16/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0029 - val_loss: 0.0032\n",
            "Epoch 17/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 18/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 19/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 20/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 21/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 22/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 23/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 24/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 25/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 26/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "Epoch 27/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 28/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 29/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 30/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 31/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 32/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0016 - val_loss: 0.0020\n",
            "Epoch 33/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 34/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0015 - val_loss: 0.0021\n",
            "Epoch 35/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 36/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0016 - val_loss: 0.0021\n",
            "Epoch 37/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 38/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 39/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 40/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 41/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 42/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 43/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 44/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 45/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 46/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 47/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 48/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 49/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 50/50\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0014 - val_loss: 0.0016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Training Loss: [0.0371051  0.00983702 0.00671967 0.00554916 0.00512822 0.00461541\n",
            " 0.00427863 0.00396144 0.00388019 0.00378087 0.00361185 0.00340499\n",
            " 0.00347098 0.00319855 0.00312108 0.00287376 0.00273219 0.00251699\n",
            " 0.00245715 0.00251166 0.00227254 0.00225142 0.00225689 0.00215396\n",
            " 0.00211606 0.00196169 0.00192106 0.00195707 0.00192045 0.00196607\n",
            " 0.0017722  0.00168426 0.00170994 0.00161877 0.00165806 0.00166612\n",
            " 0.00161783 0.00157711 0.00153454 0.00162189 0.00160092 0.00149777\n",
            " 0.00146549 0.0014615  0.00152213 0.00151836 0.00152714 0.00139376\n",
            " 0.00135539 0.00131923]\n",
            "Average Validation Loss: [0.01363924 0.00732789 0.00617947 0.00517804 0.00488968 0.00455077\n",
            " 0.00403916 0.00404577 0.00430348 0.00384389 0.00363798 0.00330435\n",
            " 0.00340142 0.00333109 0.0032783  0.00292522 0.00263959 0.00247401\n",
            " 0.00300473 0.00229932 0.00216268 0.00228771 0.0021741  0.00212987\n",
            " 0.00204556 0.00187622 0.00189464 0.00204209 0.0022735  0.00179471\n",
            " 0.0018038  0.00165176 0.00167733 0.001644   0.0017483  0.00165979\n",
            " 0.00165069 0.00154468 0.00159124 0.00164552 0.00156102 0.00152363\n",
            " 0.00145084 0.00150071 0.00153341 0.00157652 0.00143963 0.00139834\n",
            " 0.00130628 0.0013925 ]\n"
          ]
        }
      ],
      "source": [
        "# Define the number of folds\n",
        "num_folds = 5\n",
        "\n",
        "# Initialize the KFold object\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store training and validation losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "image_shape = (128, 128, 3)\n",
        "\n",
        "# Iterate over the folds\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
        "    print(f\"Training Fold {fold + 1}\")\n",
        "\n",
        "    # Get the data for this fold\n",
        "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
        "\n",
        "    # Reshape features to match image dimensions\n",
        "    X_train_fold = X_train_fold.reshape(-1, *image_shape)\n",
        "    X_val_fold = X_val_fold.reshape(-1, *image_shape)\n",
        "\n",
        "    # Build the model\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=image_shape),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', strides=2),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same', strides=2),\n",
        "        UpSampling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        UpSampling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "    # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    # batch size = 32\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_fold, X_train_fold, epochs=50, batch_size=16, validation_data=(X_val_fold, X_val_fold))\n",
        "\n",
        "    # Save training and validation losses\n",
        "    train_losses.append(history.history['loss'])\n",
        "    val_losses.append(history.history['val_loss'])\n",
        "\n",
        "    # Save the model\n",
        "    model.save(f'deblur_model_fold_{fold}.h5')\n",
        "\n",
        "# Print average training and validation losses across folds\n",
        "print(f\"Average Training Loss: {np.mean(train_losses, axis=0)}\")\n",
        "print(f\"Average Validation Loss: {np.mean(val_losses, axis=0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8ZxCSkCm-IXN"
      },
      "outputs": [],
      "source": [
        "# Define U-Net model\n",
        "def unet_model(input_size=(128, 128, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoding path\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=-1)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=-1)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=-1)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    outputs = Conv2D(3, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Compile model\n",
        "model = unet_model()\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(blur_images, sharp_images, batch_size=16, epochs=50, validation_split=0.1)\n",
        "\n",
        "# Save the model\n",
        "model.save('image_deblurring_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xunO-cq02DKT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import clone_model\n",
        "\n",
        "class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, model_builder, **kwargs):\n",
        "        self.model_builder = model_builder\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X, y = check_X_y(X, y)\n",
        "        self.classes_ = np.unique(y)\n",
        "        self.model_ = self.model_builder(**self.kwargs)\n",
        "        self.model_.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        self.model_.fit(X, y, epochs=10, batch_size=32, verbose=0)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = check_array(X)\n",
        "        y_pred = np.argmax(self.model_.predict(X), axis=1)\n",
        "        return y_pred\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return accuracy_score(y, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# You can now use wrapper with GridSearchCV or any other scikit-learn functionality\n",
        "\n",
        "\n",
        "\n",
        "# Define U-Net model\n",
        "def unet_model(input_size=(128, 128, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoding path\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=-1)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=-1)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=-1)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    outputs = Conv2D(3, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize k-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Define parameters for grid search\n",
        "param_grid = {\n",
        "    'epochs': [50, 100],\n",
        "    'batch_size': [16, 32],\n",
        "    'optimizer': ['adam', 'rmsprop']\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "best_model = GridSearchCV(estimator=unet_model(), param_grid=param_grid, cv=kf, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "best_model.fit(X, y)\n",
        "\n",
        "\n",
        "wrapper = KerasClassifierWrapper(best_model)\n",
        "# Print best parameters and score\n",
        "print(\"Best Parameters: \", best_model.best_params_)\n",
        "print(\"Best Score: \", best_model.best_score_)\n",
        "\n",
        "# Save the best model\n",
        "best_model.best_estimator_.save('best_deblur_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScgJoLYcGlKj"
      },
      "source": [
        "# **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "BK3SFmz7ij29",
        "outputId": "063bafcd-4fcf-47f7-b65b-6dc5705f364d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 128, 128, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_4'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5d8e0784084c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/image-deblur/image-deblur/models/deblur_model_fold_3.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdeblur_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    868\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    871\u001b[0m                 \u001b[0;34mf\"Error when deserializing class '{cls.__name__}' using \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;34mf\"config={config}.\\n\\nException encountered: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 128, 128, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_4'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/image-deblur/image-deblur/models/deblur_model_fold_3.h5')\n",
        "\n",
        "def deblur_image(img_path, output_path, size=(128, 128)):\n",
        "    # Load and preprocess the input image\n",
        "    img = load_img(img_path, target_size=size)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Predict using the model\n",
        "    deblurred_array = model.predict(img_array)[0]\n",
        "\n",
        "    # Convert the deblurred array to image and save\n",
        "    deblurred_img = array_to_img(deblurred_array)\n",
        "\n",
        "    # Plot both images\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title('Blur Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(deblurred_img)\n",
        "    plt.title('Predicted Sharp Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "deblur_image('/content/42_NIKON-D3400-35MM_F.JPG', '/content/out.jpg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKi00j6zPvFz",
        "outputId": "6de7aa7b-9bdd-44ff-8ca6-e37f4a4669cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 350/350 [00:12<00:00, 28.47it/s]\n",
            "100%|██████████| 350/350 [00:11<00:00, 30.86it/s]\n"
          ]
        }
      ],
      "source": [
        "# preprocess_save_images.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_and_preprocess_images(image_folder, label, prefix):\n",
        "    data = []\n",
        "    for idx, file in enumerate(tqdm(sorted(os.listdir(image_folder)))):\n",
        "        if any(file.endswith(extension) for extension in ['.jpg', '.JPG', '.jpeg', '.png']):\n",
        "            image_path = os.path.join(image_folder, file)\n",
        "            image = load_img(image_path, target_size=(128, 128))\n",
        "            image_array = img_to_array(image).astype('float32') / 255\n",
        "            image_flattened = image_array.flatten()  # Flatten the image\n",
        "            image_flattened_str = ','.join(map(str, image_flattened))  # Convert to a single string\n",
        "            pair_id = f\"{prefix}_{idx}\"\n",
        "            data.append([image_path, image_flattened_str, label, pair_id])  # Add pair_id\n",
        "    return data\n",
        "\n",
        "# Extract features\n",
        "blur_features = load_and_preprocess_images('/content/image-deblur/resized_dataset/blur', label=0, prefix='blur')\n",
        "sharp_features = load_and_preprocess_images('/content/image-deblur/resized_dataset/sharp', label=1, prefix='sharp')\n",
        "\n",
        "# Combine data and create a DataFrame\n",
        "columns = ['image_path', 'image_features', 'label', 'pair_id']\n",
        "data = sharp_features + blur_features\n",
        "features_df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Save to CSV\n",
        "features_df.to_csv('image_data.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}