{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku2vNxq_K62K",
        "outputId": "4687942d-29ef-4fd4-8cee-3ab14afadd81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'image-deblur'...\n",
            "remote: Enumerating objects: 1802, done.\u001b[K\n",
            "remote: Counting objects: 100% (1802/1802), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1795/1795), done.\u001b[K\n",
            "remote: Total 1802 (delta 9), reused 1788 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1802/1802), 39.95 MiB | 17.40 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Emeika/image-deblur.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm781KC4LUAx",
        "outputId": "1782ae2e-19f1-4789-8771-a06f9b2a533a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/image-deblur\n"
          ]
        }
      ],
      "source": [
        "cd image-deblur/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtnp6ZXaHVkQ"
      },
      "source": [
        "***Import Modules***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "joRZ4p4VUAF5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Reshape, Conv2D, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ5VCLZOFpaa"
      },
      "source": [
        "***Extract features into a feature vector and flatten them onto a csv***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P3bwVdTgO-Q1"
      },
      "outputs": [],
      "source": [
        "# the flattened feature vector directly in the CSV file, resulting in a truncated representation but doesnt load properly\n",
        "def extract_features(img_dir, label, size=(128, 128)):\n",
        "    data = []\n",
        "    for filename in os.listdir(img_dir):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n",
        "            img_path = os.path.join(img_dir, filename)\n",
        "            img = load_img(img_path, target_size=size)\n",
        "            img_array = img_to_array(img) / 255.0\n",
        "            img_flat = img_array.flatten()\n",
        "            data.append([img_path, img_flat, label])\n",
        "\n",
        "    return data\n",
        "\n",
        "# Extract features\n",
        "blur_features = extract_features('/content/image-deblur/resized_dataset/blur', label=0)\n",
        "sharp_features = extract_features('/content/image-deblur/resized_dataset/sharp', label=1)\n",
        "\n",
        "# Combine and create DataFrame\n",
        "columns = ['image_path', 'image_features', 'label']\n",
        "features_df = pd.DataFrame(blur_features + sharp_features, columns=columns)\n",
        "\n",
        "# Save to CSV\n",
        "features_df.to_csv('image_features.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y4nAtQiR02C",
        "outputId": "02c6331f-9f06-4683-d838-bdbde4255708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [00:12<00:00, 27.81it/s]\n",
            "100%|██████████| 350/350 [00:12<00:00, 28.24it/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_and_preprocess_images(image_folder, label):\n",
        "    data = []\n",
        "    for file in tqdm(sorted(os.listdir(image_folder))):\n",
        "        if any(file.endswith(extension) for extension in ['.jpg', '.JPG']):\n",
        "            image_path = os.path.join(image_folder, file)\n",
        "            image = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n",
        "            image_flattened = image.flatten()  # Flatten the image\n",
        "            image_flattened_str = ','.join(map(str, image_flattened))  # Convert to a single string\n",
        "            data.append([image_path, image_flattened_str, label])  # Add image path and label\n",
        "    return data\n",
        "\n",
        "# Extract features\n",
        "blur_features = load_and_preprocess_images('/content/image-deblur/resized_dataset/blur', label=0)\n",
        "sharp_features = load_and_preprocess_images('/content/image-deblur/resized_dataset/sharp', label=1)\n",
        "\n",
        "# Combine data and create a DataFrame\n",
        "columns = ['image_path', 'image_features', 'label']\n",
        "data = sharp_features + blur_features\n",
        "features_df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Save to CSV\n",
        "features_df.to_csv('image_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIaN9Ym_HMIn"
      },
      "source": [
        "***Load Data***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_csv(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    image_paths = df['image_path'].values\n",
        "    labels = df['label'].values\n",
        "    image_data = df['image_features'].apply(lambda x: np.fromstring(x, sep=',')).values\n",
        "    images = np.array([img.reshape(128, 128, 3) for img in image_data])  # Reshape to original dimensions\n",
        "    return images, image_paths, labels\n",
        "\n",
        "# Load images from CSV\n",
        "images_loaded, image_paths_loaded, labels_loaded = load_images_from_csv('image_data.csv')\n",
        "\n",
        "print(images_loaded.shape)  # Should be (num_images, 128, 128, 3)\n",
        "print(image_paths_loaded.shape)  # Should be (num_images,)\n",
        "print(labels_loaded.shape)  # Should be (num_images,)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vHdjbJ2ks6u",
        "outputId": "3f4af78e-5907-4aa9-b3b0-2de4ca5a242e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(700, 128, 128, 3)\n",
            "(700,)\n",
            "(700,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvQhE5TTHQ7Y"
      },
      "outputs": [],
      "source": [
        "# Step 1: Read the CSV file\n",
        "# data = pd.read_csv('image_features.csv')\n",
        "\n",
        "\n",
        "# # Step 2: Parse the numpy array strings into actual numpy arrays\n",
        "# data['image_features'] = data['image_features'].apply(lambda x: np.fromstring(x[1:-1], sep=' '))\n",
        "\n",
        "# # data['image_features'] = data['image_features'].apply(lambda x: x.reshape(128, 128, 3))\n",
        "\n",
        "# # # Check that the features length is 49152\n",
        "# num_samples = data.shape[0]\n",
        "# feature_length = data['image_features'].apply(len).unique()\n",
        "# assert len(feature_length) == 1 and feature_length[0] == 128 * 128 * 3, \\\n",
        "#     f\"Expected features of length {128 * 128 * 3}, but got {feature_length}\"\n",
        "\n",
        "# Step 3: Reshape the data for training\n",
        "# X = np.vstack(data['image_features'].values)\n",
        "# y = data['label'].values\n",
        "# print(X.shape)\n",
        "# image_shape = (128, 128, 3)\n",
        "# X_reshaped = X.reshape(-1, *image_shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkU6o8yBGe5R"
      },
      "source": [
        "***Train Model by Split into Training, Testing and Validation set using kfolds cross validation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjJngwCa8oDP",
        "outputId": "f81f1f6f-5b8a-49d6-eef8-5bd88e4bd004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Fold 1\n",
            "Epoch 1/50\n",
            "35/35 [==============================] - 326s 9s/step - loss: 0.0351 - val_loss: 0.0126\n",
            "Epoch 2/50\n",
            "35/35 [==============================] - 307s 9s/step - loss: 0.0095 - val_loss: 0.0071\n",
            "Epoch 3/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0065"
          ]
        }
      ],
      "source": [
        "# Define the number of folds\n",
        "num_folds = 5\n",
        "\n",
        "# Initialize the KFold object\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store training and validation losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "image_shape = (128, 128, 3)\n",
        "\n",
        "# Iterate over the folds\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(images_loaded)):\n",
        "    print(f\"Training Fold {fold + 1}\")\n",
        "\n",
        "    # Get the data for this fold\n",
        "    X_train_fold, X_val_fold = images_loaded[train_index], images_loaded[val_index]\n",
        "\n",
        "    # Reshape features to match image dimensions\n",
        "    X_train_fold = X_train_fold.reshape(-1, *image_shape)\n",
        "    X_val_fold = X_val_fold.reshape(-1, *image_shape)\n",
        "\n",
        "    # Build the model\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=image_shape),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', strides=2),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same', strides=2),\n",
        "        UpSampling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        UpSampling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "    # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    # batch size = 32\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_fold, X_train_fold, epochs=50, batch_size=16, validation_data=(X_val_fold, X_val_fold))\n",
        "\n",
        "    # Save training and validation losses\n",
        "    train_losses.append(history.history['loss'])\n",
        "    val_losses.append(history.history['val_loss'])\n",
        "\n",
        "    # Save the model\n",
        "    model.save(f'deblur_model_fold_{fold}.h5')\n",
        "\n",
        "# Print average training and validation losses across folds\n",
        "print(f\"Average Training Loss: {np.mean(train_losses, axis=0)}\")\n",
        "print(f\"Average Validation Loss: {np.mean(val_losses, axis=0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZxCSkCm-IXN",
        "outputId": "c7ef2249-ddc7-4932-97e6-855bdae7e503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 459s 28s/step - loss: 0.0703 - accuracy: 0.6405 - val_loss: 0.0700 - val_accuracy: 0.6995\n",
            "Epoch 2/50\n",
            "11/16 [===================>..........] - ETA: 2:24 - loss: 0.0690 - accuracy: 0.6596"
          ]
        }
      ],
      "source": [
        "# Define U-Net model\n",
        "def unet_model(input_size=(128, 128, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoding path\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=-1)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=-1)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=-1)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    outputs = Conv2D(3, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Compile model\n",
        "model = unet_model()\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(blur_images, sharp_images, batch_size=16, epochs=50, validation_split=0.1)\n",
        "\n",
        "# Save the model\n",
        "model.save('image_deblurring_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define U-Net model\n",
        "def unet_model(input_size=(128, 128, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoding path\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoding path\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=-1)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=-1)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=-1)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    outputs = Conv2D(3, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Data\n",
        "images = np.concatenate((blur_images, sharp_images), axis=0)  # Concatenate blur and sharp images\n",
        "labels = np.concatenate((np.zeros(blur_images.shape[0]), np.ones(sharp_images.shape[0])))  # Labels (0 for blur, 1 for sharp)\n",
        "\n",
        "# Initialize k-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Define parameters for grid search\n",
        "param_grid = {\n",
        "    'epochs': [50, 100],\n",
        "    'batch_size': [16, 32],\n",
        "    'optimizer': ['adam', 'rmsprop']\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "best_model = GridSearchCV(estimator=unet_model(), param_grid=param_grid, cv=kf, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "best_model.fit(images, labels)\n",
        "\n",
        "# Print best parameters and score\n",
        "print(\"Best Parameters: \", best_model.best_params_)\n",
        "print(\"Best Score: \", best_model.best_score_)\n",
        "\n",
        "# Save the best model\n",
        "best_model.best_estimator_.save('best_deblur_model.h5')\n"
      ],
      "metadata": {
        "id": "xunO-cq02DKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScgJoLYcGlKj"
      },
      "source": [
        "# **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK3SFmz7ij29"
      },
      "outputs": [],
      "source": [
        "model = load_model('deblur_model.h5')\n",
        "\n",
        "def deblur_image(img_path, output_path, size=(128, 128)):\n",
        "    img = load_img(img_path, target_size=size)\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    img_flat = img_array.flatten()\n",
        "    img_flat = np.expand_dims(img_flat, axis=0)\n",
        "\n",
        "    deblurred_flat = model.predict(img_flat)[0]\n",
        "    deblurred_array = deblurred_flat.reshape(size + (3,))\n",
        "    deblurred_img = array_to_img(deblurred_array)\n",
        "    deblurred_img.save(output_path)\n",
        "\n",
        "# Example usage\n",
        "deblur_image('path/to/blurry/image.jpg', 'path/to/output/image.jpg')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}